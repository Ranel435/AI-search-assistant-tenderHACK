services:
  # Nginx как основной маршрутизатор запросов
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"      # HTTP
      - "443:443"    # HTTPS
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro  # Сертификаты
    depends_on:
      # - frontend
      - backend
    restart: always

  # # Фронтенд-приложение
  # frontend:
  #   build: ./frontend
  #   ports:
  #     - "3000:80"  # В production через Nginx
  #   volumes:
  #     - ./frontend/dist:/usr/share/nginx/html:ro
  #     - ./frontend/nginx.conf:/etc/nginx/conf.d/default.conf:ro
  #   restart: always
  #   depends_on:
  #     - backend

  # Бэкенд API
  backend:
    build: ./backend
    ports:
      - "8080:8080"
    environment:
      - SERVER_ADDRESS=:8080
      - DB_HOST=${DB_HOST}
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - DB_NAME=${DB_NAME}
      - DB_SSLMODE=${DB_SSLMODE}
      - LLM_SERVICE_URL=http://llm_service:8000
    depends_on:
      - postgres
      # - llm_service
    restart: always
    volumes:
      - ./data:/app/data

  # LLM сервис
  # llm_service:
  #   image: ollama/ollama:latest
  #   ports:
  #     - "8000:8000"
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   restart: always
  #   # Или используйте альтернативный сервис с моделью на выбор:
  #   # image: ghcr.io/huggingface/text-generation-inference:latest
  #   # environment:
  #   #   - MODEL_ID=mistralai/Mistral-7B-Instruct-v0.2

  # Векторная база данных (Qdrant)
  # vector_db:
  #   image: qdrant/qdrant:latest
  #   volumes:
  #     - vector_data:/qdrant/storage
  #   restart: always

  # База данных PostgreSQL
  postgres:
    image: postgres:16-alpine
    environment:
      - POSTGRES_USER=${DB_USER}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_DB=${DB_NAME}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/migrations:/docker-entrypoint-initdb.d
    restart: always
    # deploy:
    #   resources:
    #     limits:
    #       cpus: '2'
    #       memory: 2G

  # Сервис для индексации документов (запускается периодически)
  # indexer:
  #   build: ./backend
  #   command: ["go", "run", "cmd/indexer/main.go"]
  #   volumes:
  #     - ./knowledge_base:/knowledge_base
  #   depends_on:
  #     - vector_db
  #     - llm_service
  #   restart: "no"  # Запускается вручную или по расписанию

volumes:
  postgres_data:
  vector_data:
  ollama_data:
